{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"}],"dockerImageVersionId":30370,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import libraries","metadata":{}},{"cell_type":"code","source":"import cv2 as cv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport zipfile\nfrom collections import Counter\nfrom scipy.cluster.vq import *\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T13:19:22.512351Z","iopub.execute_input":"2024-04-14T13:19:22.512818Z","iopub.status.idle":"2024-04-14T13:19:22.519960Z","shell.execute_reply.started":"2024-04-14T13:19:22.512784Z","shell.execute_reply":"2024-04-14T13:19:22.518800Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"function get_image_names to get all file names within the dataset, which is later on used to determine splitting among train and test data","metadata":{}},{"cell_type":"code","source":"def get_image_names(root_path):\n    names = os.listdir(root_path)\n    return names","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.522343Z","iopub.execute_input":"2024-04-14T13:19:22.523357Z","iopub.status.idle":"2024-04-14T13:19:22.531626Z","shell.execute_reply.started":"2024-04-14T13:19:22.523308Z","shell.execute_reply":"2024-04-14T13:19:22.530758Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"function get_images is to get the images listed in img_name_list from the given root path","metadata":{}},{"cell_type":"code","source":"def get_images(root_path, img_name_list):\n    img_list = []\n    img_class_list = []\n    \n    for img_name in img_name_list:\n        img_path = root_path + '/' + img_name\n        img = cv.imread(img_path)\n        img_list.append(img)\n        \n        if ('cat' in img_name):\n            img_class_list.append(0)\n        elif ('dog' in img_name):\n            img_class_list.append(1)\n    \n    return img_list, img_class_list","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.532742Z","iopub.execute_input":"2024-04-14T13:19:22.533038Z","iopub.status.idle":"2024-04-14T13:19:22.541703Z","shell.execute_reply.started":"2024-04-14T13:19:22.533009Z","shell.execute_reply":"2024-04-14T13:19:22.540932Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Bag of Visual Words (BoVW)**\n\nConsists of 3 parts:\n1. Feature detection and description (we used SIFT)\n2. Dictionary/codewords generation (perform k-means clustering over all vectors. The resulting center of cluters are the codewords/visual words, which represent similar image patches.)\n3. Vector quantization (comparing the distances between visual words with the images' features using scipy.cluster.vq. If the current feature descriptor is closer to centroid/visual word i, then it belongs to cluster i. This will produce a histogram (the bag of words) for each image, which represent the frequency of visual words in the image.","metadata":{}},{"cell_type":"markdown","source":"Extract image descriptors using SIFT","metadata":{}},{"cell_type":"code","source":"def get_sift_descriptors(img_list):\n    sift = cv.SIFT_create()\n    descriptor_list = []\n\n    for img in img_list:\n        _, descriptors = sift.detectAndCompute(img, None)\n        descriptor_list.append(descriptors)\n    \n    return descriptor_list","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.543356Z","iopub.execute_input":"2024-04-14T13:19:22.543689Z","iopub.status.idle":"2024-04-14T13:19:22.550993Z","shell.execute_reply.started":"2024-04-14T13:19:22.543660Z","shell.execute_reply":"2024-04-14T13:19:22.550221Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Elbow method (wcss)","metadata":{}},{"cell_type":"code","source":"def elbow_method_cluster(descriptor_list):\n    stacked_descriptors = descriptor_list[0]\n    for descriptor in descriptor_list[1:]:\n        stacked_descriptors = np.vstack((stacked_descriptors, descriptor))\n    stacked_descriptors = np.float32(stacked_descriptors)\n    \n    wcss = []\n    k_values = []\n    for i in range(1, 10):\n        clustering = KMeans(n_clusters=i, init='k-means++', random_state=42)\n        clustering.fit(stacked_descriptors)\n        wcss.append(clustering.inertia_)\n        k_values.append(i)\n    \n    plt.plot(wcss, marker='o')\n    plt.xticks(np.arange(0, len(wcss)), k_values)\n    plt.title('Elbow Method: WCSS vs K (number of clusters)')\n    plt.xlabel('K')\n    plt.ylabel('Inertia')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.552929Z","iopub.execute_input":"2024-04-14T13:19:22.553260Z","iopub.status.idle":"2024-04-14T13:19:22.563294Z","shell.execute_reply.started":"2024-04-14T13:19:22.553233Z","shell.execute_reply":"2024-04-14T13:19:22.562239Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Clustering (creating centroids) using K-means, in which we will experiment with k (number of clusters) of 2 (based on number of class, dog and cat) and custom (optimal number, based on elbow method/wcss)","metadata":{}},{"cell_type":"code","source":"def clustering(descriptor_list, k):\n    stacked_descriptors = descriptor_list[0]\n    for descriptor in descriptor_list[1:]:\n        stacked_descriptors = np.vstack((stacked_descriptors, descriptor))\n    stacked_descriptors = np.float32(stacked_descriptors)\n    \n    centroids, _ = kmeans(stacked_descriptors, k, 20)\n\n    return centroids","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.564461Z","iopub.execute_input":"2024-04-14T13:19:22.564762Z","iopub.status.idle":"2024-04-14T13:19:22.578130Z","shell.execute_reply.started":"2024-04-14T13:19:22.564727Z","shell.execute_reply":"2024-04-14T13:19:22.577186Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Vector quantization (Bag of Words)\n","metadata":{}},{"cell_type":"code","source":"def vector_quantization(descriptor_list, number_of_images, centroids):\n    image_features = np.zeros((number_of_images, len(centroids)), \"float32\")\n\n    for i in range(number_of_images):\n        words, _ = vq(descriptor_list[i], centroids)\n        for w in words:\n            image_features[i][w] += 1\n\n    return image_features","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.580539Z","iopub.execute_input":"2024-04-14T13:19:22.581269Z","iopub.status.idle":"2024-04-14T13:19:22.587970Z","shell.execute_reply.started":"2024-04-14T13:19:22.581236Z","shell.execute_reply":"2024-04-14T13:19:22.587006Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Histogram normalization using standard scaler, where data is scaled to a standard deviation of 1 and mean of 0, so that the histogram's frequencies are distributed to a wider range.","metadata":{}},{"cell_type":"code","source":"def normalization(img_feature_list):\n    stdscaler = StandardScaler().fit(img_feature_list)\n    img_feature_list = stdscaler.transform(img_feature_list)\n\n    return img_feature_list","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.589164Z","iopub.execute_input":"2024-04-14T13:19:22.589438Z","iopub.status.idle":"2024-04-14T13:19:22.598339Z","shell.execute_reply.started":"2024-04-14T13:19:22.589401Z","shell.execute_reply":"2024-04-14T13:19:22.597527Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Classification using nearest neighbors**\n\nElbow method to determine the optimal number of k (nearest neighbors) in KNN by plotting error rate. Only odd numbers are considered in order to have a tiebreaker.","metadata":{}},{"cell_type":"code","source":"def elbow_method_neighbor(train_feature_list, train_class_list, test_feature_list, test_class_list):\n    error_rate = []\n    min_error = 100\n    min_idx = -1\n    for i in range(1, 300, 2):\n        knn = KNeighborsClassifier(n_neighbors=i)\n        knn.fit(train_feature_list, train_class_list)\n        pred_i = knn.predict(test_feature_list)\n        err = np.mean(pred_i != test_class_list)\n        error_rate.append(err)\n        \n        if (err < min_error):\n            min_error = err\n            min_idx = i\n        \n    k_values = [1]\n    for i in range(10, 301, 10):\n        k_values.append(i)\n    \n    print(\"Minimum error rate is at k = \", min_idx, \"with error rate of \", min_error)\n    plt.figure(figsize=(20, 5))\n    plt.plot(error_rate, marker='o')\n    plt.xticks(np.arange(0, 151, 5), k_values)\n    plt.title('Elbow Method: Error rate vs K (number of neighbors)')\n    plt.xlabel('K')\n    plt.ylabel('Error Rate')\n    plt.show()\n    \n    return min_idx, min_error","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.599608Z","iopub.execute_input":"2024-04-14T13:19:22.599932Z","iopub.status.idle":"2024-04-14T13:19:22.610993Z","shell.execute_reply.started":"2024-04-14T13:19:22.599905Z","shell.execute_reply":"2024-04-14T13:19:22.610100Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"KNN\n\nK-nearest neighbors is a supervised machine learning algorithm that is used to make classification or prediction. Since this is a classification task, then the algorithm must determine whether an object is a 'Dog' or 'Cat'. To determine this, KNN uses a technique called 'majority voting' or simply checks the K nearest points and  predict the class based on the voting of the most frequent class.","metadata":{}},{"cell_type":"code","source":"def KNN(train_feature_list, train_class_list, test_feature_list, test_class_list, k):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(train_feature_list, train_class_list)\n\n    results = knn.predict(test_feature_list)\n    return results","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.612391Z","iopub.execute_input":"2024-04-14T13:19:22.612787Z","iopub.status.idle":"2024-04-14T13:19:22.624106Z","shell.execute_reply.started":"2024-04-14T13:19:22.612746Z","shell.execute_reply":"2024-04-14T13:19:22.623228Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"**Main code**\n\nOur KNN experiment consists of 2 models:\n1. KNN with 2 clusters/centroids and elbow method observation-based number of neighbors\n2. KNN with elbow method observation-based number of clusters and also elbow method observation-based number of neighbors","metadata":{}},{"cell_type":"code","source":"with zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\",'r') as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:19:22.625390Z","iopub.execute_input":"2024-04-14T13:19:22.625702Z","iopub.status.idle":"2024-04-14T13:19:33.177456Z","shell.execute_reply.started":"2024-04-14T13:19:22.625673Z","shell.execute_reply":"2024-04-14T13:19:33.176315Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Read and split train and test images","metadata":{}},{"cell_type":"code","source":"root_path = \"./train\"\nimg_name_list = get_image_names(root_path)\ntrain_name_list, test_name_list = train_test_split(img_name_list, test_size=0.1, random_state=42)\n\ntrain_name_list = train_name_list[:4200]\ntest_name_list = test_name_list[:1800]\n\ntrain_image_list, train_class_list = get_images(root_path, train_name_list)\ntest_image_list, test_class_list = get_images(root_path, test_name_list)\n\nprint(\"Number of train images = \", len(train_image_list))\nprint(Counter(train_class_list))\nprint(\"Number of test images = \", len(test_image_list))\nprint(Counter(test_class_list))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:22:17.608413Z","iopub.execute_input":"2024-04-14T13:22:17.609179Z","iopub.status.idle":"2024-04-14T13:22:29.830999Z","shell.execute_reply.started":"2024-04-14T13:22:17.609141Z","shell.execute_reply":"2024-04-14T13:22:29.830026Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Number of train images =  4200\nCounter({0: 2144, 1: 2056})\nNumber of test images =  1800\nCounter({0: 911, 1: 889})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Due to memory limit issues, the total of images being used is 6000 out of 25000, with ratio between train and test data being 9:1. The counter above show the distribution of classes in train and test dataset; 0 for cat and 1 for dog. The numbers show that they are balanced.","metadata":{}},{"cell_type":"code","source":"train_descriptor_list = get_sift_descriptors(train_image_list)\ntest_descriptor_list = get_sift_descriptors(test_image_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:22:40.819037Z","iopub.execute_input":"2024-04-14T13:22:40.819813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(1) KNN with 2 clusters/centroids and elbow method observation-based number of neighbors\n\nUnder a simple logic that the number of categories in this dataset is 2 (dog and cat), our first attempt uses k (number of clusters) = 2.","metadata":{}},{"cell_type":"code","source":"centroids = clustering(train_descriptor_list, 2)\ntrain_feature_list = vector_quantization(train_descriptor_list, len(train_image_list), centroids)\ntrain_feature_list = normalization(train_feature_list)\n\ntest_feature_list = vector_quantization(test_descriptor_list, len(test_image_list), centroids)\ntest_feature_list = normalization(test_feature_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.939462Z","iopub.status.idle":"2024-04-14T13:21:40.939883Z","shell.execute_reply.started":"2024-04-14T13:21:40.939686Z","shell.execute_reply":"2024-04-14T13:21:40.939705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_error_idx, min_error_val = elbow_method_neighbor(train_feature_list, train_class_list, test_feature_list, test_class_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.941447Z","iopub.status.idle":"2024-04-14T13:21:40.941852Z","shell.execute_reply.started":"2024-04-14T13:21:40.941672Z","shell.execute_reply":"2024-04-14T13:21:40.941689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using elbow method, we can observe the error rates as visualized by the plot above, and the global minima is found at k=41, with an error rate of 0.39. At the same time, through visual observation, we can see that the plot only continues to averagely decrease until +- k = 40. Therefore, we can conclude that the elbow is located at the same point as the global minima, which is k = 41.","metadata":{}},{"cell_type":"code","source":"results = KNN(train_feature_list, train_class_list, test_feature_list, test_class_list, 41)\n\nconf_matrix = confusion_matrix(test_class_list, results)\nax = seaborn.heatmap(conf_matrix, xticklabels='01', yticklabels='01', annot=True, cmap='Blues', fmt='g')\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.942864Z","iopub.status.idle":"2024-04-14T13:21:40.943250Z","shell.execute_reply.started":"2024-04-14T13:21:40.943070Z","shell.execute_reply":"2024-04-14T13:21:40.943087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_class_list, results, target_names=['Cat', 'Dog']))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.944454Z","iopub.status.idle":"2024-04-14T13:21:40.944795Z","shell.execute_reply.started":"2024-04-14T13:21:40.944626Z","shell.execute_reply":"2024-04-14T13:21:40.944641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(2) KNN with elbow method observation-based number of clusters and also elbow method observation-based number of neighbors\n\nHowever, when observing the dataset, it is apparent that there are diverse images with different types of dogs and cats. It would make sense to have a multicluster KNN, where the number of cluster not only represents cats/dogs, but might also help differentiating subtypes of cats/dogs. In order to find this optimal number of clusters, we use elbow method with WCSS.","metadata":{}},{"cell_type":"code","source":"elbow_method_cluster(train_descriptor_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.946387Z","iopub.status.idle":"2024-04-14T13:21:40.946726Z","shell.execute_reply.started":"2024-04-14T13:21:40.946559Z","shell.execute_reply":"2024-04-14T13:21:40.946574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The WCSS plot shows that the elbow (or bend) is at either k = 3 or k = 4 clusters; yet it is more obvious to observe that the curve after k = 3 has formed an almost straight, flat line. Therefore, the optimal number of clusters we will use is 3.","metadata":{}},{"cell_type":"code","source":"centroids = clustering(train_descriptor_list, 3)\ntrain_feature_list = vector_quantization(train_descriptor_list, len(train_image_list), centroids)\ntrain_feature_list = normalization(train_feature_list)\n\ntest_feature_list = vector_quantization(test_descriptor_list, len(test_image_list), centroids)\ntest_feature_list = normalization(test_feature_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.948066Z","iopub.status.idle":"2024-04-14T13:21:40.948452Z","shell.execute_reply.started":"2024-04-14T13:21:40.948243Z","shell.execute_reply":"2024-04-14T13:21:40.948283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_error_idx, min_error_val = elbow_method_neighbor(train_feature_list, train_class_list, test_feature_list, test_class_list)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.949887Z","iopub.status.idle":"2024-04-14T13:21:40.950266Z","shell.execute_reply.started":"2024-04-14T13:21:40.950094Z","shell.execute_reply":"2024-04-14T13:21:40.950110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This plot also doesn't show a proper curve, which imply that the clusters in this model most likely had irregular shapes. However, although the global minima is located at k = 73 neighbors, we can observe that the error rate averagely decreases until +- k = 60.\nTherefore, we can conclude that the elbow is located k = 61.","metadata":{}},{"cell_type":"code","source":"results = KNN(train_feature_list, train_class_list, test_feature_list, test_class_list, 61)\n\nconf_matrix = confusion_matrix(test_class_list, results)\nax = seaborn.heatmap(conf_matrix, xticklabels='01', yticklabels='01', annot=True, cmap='Blues', fmt='g')\nax.set_xlabel('Actual')\nax.set_ylabel('Predicted')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.951227Z","iopub.status.idle":"2024-04-14T13:21:40.951555Z","shell.execute_reply.started":"2024-04-14T13:21:40.951389Z","shell.execute_reply":"2024-04-14T13:21:40.951403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(test_class_list, results, target_names=['Cat', 'Dog']))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.952800Z","iopub.status.idle":"2024-04-14T13:21:40.953177Z","shell.execute_reply.started":"2024-04-14T13:21:40.952998Z","shell.execute_reply":"2024-04-14T13:21:40.953015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In conclusion, with the Dogs vs Cats dataset, KNN with 2 clusters obtained a test accuracy of 61%, while KNN with optimal number of clusters (k = 3) resulted in a test accuracy of 59%. It turns out that there are no improvements after a custom optimal value of k (clusters) are chosen using elbow method (WCSS). This is likely to have happened due to the cluster's irregular shapes, which can be proven from the improper curves of error rate plots.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10, 30))\nlabels = [\"Cat\", \"Dog\"]\nfor i in range(30):\n    plt.xticks([])\n    plt.yticks([])\n    plt.subplot(6, 5, i + 1)\n    plt.imshow(cv.cvtColor(test_image_list[i], cv.COLOR_BGR2RGB))\n    plt.title(labels[results[i]])\nprint(\"Preview of 30 Random KNN Classification Results (with 2nd model)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T13:21:40.954803Z","iopub.status.idle":"2024-04-14T13:21:40.955356Z","shell.execute_reply.started":"2024-04-14T13:21:40.955070Z","shell.execute_reply":"2024-04-14T13:21:40.955095Z"},"trusted":true},"execution_count":null,"outputs":[]}]}